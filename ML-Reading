Machine Learning 阅读笔记

1.1.1 机器学习的种类
1）预测性 监督学习（Predictive Supervised Learning）
training input：features, attributes or covariates
more example：an image, a sentence, an email message, a time series, a molecular shape, a graph, etc
如果y是categorical，是Classification或者Pattern Recognition。
如果y是numerical，是regression。（注意：Ordinal regression，y本身有natural ordering）。
2）描述性 无监督学习（Descriptive Unsupervised Learning）
3）强化学习（这本书暂不讨论）

1.2 监督学习
1.2.1 Classification分类
number of class=2: binary classification
number of class>2: multiclass classification
（If the class labels are not mutually exclusive (e.g., somebody may be
classified as tall and strong), we call it multi-label classification）

1.2.1.3现实生活中的实现
Document classification and email spam filtering
Classifying flowers
Image classification and handwriting recognition
Face detection and recognition
sliding window detector 识别face-like texture

补充说明：Object Localization 是深度学习Object Detection 演算法
／Sliding Windows是最简单的做法但要扫描多次 丢到CNN中去分类，速度较慢
／什么是R-CNN？
1）预选筛选出可能的2000个区域Region Proposals
2）用训练好的CNN模型如AlexNet摘取特征
3）SVM (Support Vector Machine）分类器区分物体或背影
4）线性回归模型确定bounding box
RNN使用Selctive Search筛选Region Proposals
Selective Search基于Graph Base Image Segmentation 
Link：https://medium.com/@syshen/%E7%89%A9%E9%AB%94%E5%81%B5%E6%B8%AC-object-detection-740096ec4540

1.2.2 Regression

1.3 无监督学习
1.3.1 Discovering Clusters 聚类
关于用户画像的补充
用户数据-动态信息数据／静态信息数据
1）清洗数据 2）因素分析 3）相关分析 4）聚类分析
1.3.2 发现潜在因子（Latent Factors）
/ there may only be a small number of degrees of variability, corresponding to latent factors.
For example, when modeling the appearance of face images, there may only be a few underlying
latent factors which describe most of the variability, such as lighting, pose, identity, etc.
* Low dimensional representations are useful for enabling fastnearest neighbor searches and 
two dimensional projections are very useful for visualizing high dimensional data.
PCA 主成分分析---可以看作是线性回归的无监督学习
注：计算机图像中，用来投射动图到低维空间。
In computer graphics, it is common to project motion capture data to a low dimensional
space, and use it to create animations

1.3.3 发现图片结构
* To discover new knowledge, and to get better joint probability density estimators.

1.3.4 Matrix Completion
1.3.4.1 Image Impainting
1.3.4.2 Collaborative filtering

1.4 机器学习的一些基本概念
参数（参数固定）／非参数模型（参数增长）
1.4.2 简单的非参数模型：
KNN分类器

1.4.3 The curse of dimensionality
KNN不适合高维的数据

1.4.4 分类和回归的参数模型
1.4.5 线性回归
1.4.6 逻辑回归
Induce a decision rule
1.4.7 Overfitting
1.4.8 模型选择
Misclassification Rate
Cross Validation

